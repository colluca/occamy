{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6a4851-436a-4278-9563-fe60b283a829",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018cdf4-4eac-434f-ab48-c86c9ee61541",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pandas plotly pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c1118-51c5-4a82-9226-b01df47c40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import os, glob, re, datetime, time, shutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import plotly as plotly, plotly.express as px\n",
    "import hjson\n",
    "from ruamel.yaml import YAML ## use instead of pyyaml\n",
    "yaml = YAML()\n",
    "# yaml.default_flow_style = False\n",
    "\n",
    "# Helper methods\n",
    "def slugify(text: str):\n",
    "    text = re.sub(r'[\\':{\\}]', '', text)\n",
    "    text = re.sub(r'\\s', '_', text)\n",
    "    text = re.sub(r',', '_', text)\n",
    "    return re.sub(r'\\W', '', text)\n",
    "    return text\n",
    "\n",
    "# yaml dump np types\n",
    "def represent_numpy_float64(self, value):\n",
    "    return self.represent_float(value)  # alternatively dump as a tagged float\n",
    "\n",
    "def represent_numpy_int64(self, value):\n",
    "    return self.represent_int(value)  # alternatively dump as a tagged int\n",
    "\n",
    "def represent_numpy_array(self, array, flow_style=None):\n",
    "    tag = '' # '!numpy.ndarray'\n",
    "    value = []\n",
    "    node = ruamel.yaml.nodes.SequenceNode(tag, value, flow_style=flow_style)\n",
    "    for elem in array:\n",
    "        node_elem = self.represent_data(elem)\n",
    "        value.append(node_elem)\n",
    "    if flow_style is None:\n",
    "        node.flow_style = True\n",
    "    return node\n",
    "\n",
    "yaml.Representer.add_representer(np.ndarray, represent_numpy_array)\n",
    "yaml.Representer.add_representer(np.float64, represent_numpy_float64)\n",
    "yaml.Representer.add_representer(np.int64, represent_numpy_int64)\n",
    "\n",
    "# Compatability with outside of jupyter\n",
    "import subprocess\n",
    "def run(cmd, env=None, dryrun=False):\n",
    "    if dryrun:\n",
    "        print(cmd)\n",
    "    else:\n",
    "        p = subprocess.Popen(cmd, env=env, shell=True)\n",
    "        retcode = p.wait()\n",
    "        if retcode != 0:\n",
    "            sys.exit(retcode)\n",
    "\n",
    "def extend_environment(env=None, **kwargs):\n",
    "    if not env:\n",
    "        env = os.environ.copy()\n",
    "    env.update(kwargs)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b290ae6-8b45-4999-8f71-098178418066",
   "metadata": {},
   "source": [
    "## Workflow for a simulating single app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff8e0ac-8b91-4ac1-b9f1-5da08ff143e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile hardware for Questa (vsim)\n",
    "!questa-2022.3 make bin/snitch_cluster.vsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e62def-f903-455e-994a-6661c8b8895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile software\n",
    "!make DEBUG=ON sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ab542-924c-4c02-a507-6044c4b32169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post process traces\n",
    "!make -j traces\n",
    "!make logs/perf.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caceab4-f9cd-474a-9ce2-8688d05317d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read profile data\n",
    "perf = pd.read_csv('logs/perf.csv', index_col=0)\n",
    "perf.filter(regex=(\"1_.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20fe0e3-3f04-4a05-ab11-3d016dc75e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some results\n",
    "fig = px.scatter(perf, y=['1_total_ipc', '1_fpss_occupancy', '1_fpss_fpu_occupancy', '1_snitch_occupancy'])\n",
    "fig.update_layout(yaxis_range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28811c2e-63ee-4143-ad82-4d97420b9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!make CFG_OVERRIDE={cfg_file} rtl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d766185-bd6c-4c21-bbf8-79eded2247f1",
   "metadata": {},
   "source": [
    "# Benchmark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96393e95-7390-4157-9314-af5155f46f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load top-level benchmark config, where all sweep information is stored\n",
    "bench_config_name = Path('bench/bench.yaml')\n",
    "with open(bench_config_name) as f:\n",
    "    bench_config = yaml.load(f)\n",
    "bench_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537b79f-0d5d-48d3-8662-bd6db2ef05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten into a table\n",
    "hw = pd.json_normalize(bench_config['hw']).add_prefix('hw.').convert_dtypes()\n",
    "sw = pd.json_normalize(bench_config['sw']).add_prefix('sw.').convert_dtypes()\n",
    "configs = hw.merge(sw, how='cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f9aea-c801-4c1b-a1ab-2c70fc782aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate expressions, any property ending in .eval is executed\n",
    "eval_cols = configs.filter(regex=(r'.*\\.eval')).columns.tolist()\n",
    "eval_cols_short = [x.removesuffix('.eval') for x in eval_cols]\n",
    "for i, col in enumerate(eval_cols):\n",
    "    short = eval_cols_short[i]\n",
    "    print(short)\n",
    "    configs[col] = configs[col].apply(lambda x: eval(x) if type(x) == str else x)            \n",
    "    \n",
    "configs.rename(dict(zip(eval_cols, eval_cols_short)), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40f6f7-4cc5-495d-925b-86c41d31df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode sweep arrays to get all combinations to run\n",
    "# each row is now a single test\n",
    "for col in configs.columns.tolist():\n",
    "    if 'sweep.' in col:\n",
    "        configs = configs.explode(col)\n",
    "        # configs.rename({col: col.replace('sweep.', '')}, axis=1, inplace=True)\n",
    "configs.reset_index(inplace=True, drop=True)\n",
    "configs = configs.convert_dtypes()\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24765e2c-d71b-4af5-a6b0-d0ef2de1377a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac025c0-3270-4823-8204-418e31e22652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_hw(config: str):\n",
    "    print(f'Compiling hw: {config}')\n",
    "\n",
    "def compile_sw(config: str):\n",
    "    print(f'Compiling sw: ')\n",
    "\n",
    "def write_test_configs(test: dict, app_config: dict, destination: Path):\n",
    "    os.makedirs(destination, exist_ok=True)\n",
    "\n",
    "    # Store full config row\n",
    "    with open(str(destination / 'test-config.yaml'), 'w') as f:\n",
    "        yaml.dump(test, f)\n",
    "\n",
    "    # Store only sw config for datagen\n",
    "    with open(destination / 'config.yaml', 'w') as f:\n",
    "        yaml.dump(app_config, f)\n",
    "    \n",
    "def prepare_output(output_dir: Path, bench_config_name: Path):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    shutil.copy(bench_config_name, output_dir / bench_config_name.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09539ef4-0b02-4253-a095-26611601820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output directory \n",
    "output_dir = Path('output')\n",
    "prepare_output(output_dir, bench_config_name)\n",
    "\n",
    "# Iterate over all tests, create the configs, compile, run and post process\n",
    "\n",
    "for hw_config, hw_config_df in configs.groupby(by='hw.config'):\n",
    "    \n",
    "    compile_hw(hw_config)\n",
    "    for app_config, app_config_df in hw_config_df.groupby(by='sw.app'):\n",
    "        \n",
    "        app_cols   = [col for col in app_config_df.columns if f'{app_config}'       in col]\n",
    "        sweep_cols = [col for col in config_app_df.columns if f'{app_config}.sweep' in col]\n",
    "        print(f'{app_config} sweeps: {sweep_cols}')\n",
    "        \n",
    "        for sweep, sweep_df in app_config_df.groupby(by=sweep_cols) if sweep_cols else {'test': app_config_df}:\n",
    "            for i, test in sweep_df.iterrows(): # (should be a df with one entry)\n",
    "                # Remove unused properties\n",
    "                test = test.dropna()\n",
    "                \n",
    "                # Get dicts for app/sweep config and remove prefixes\n",
    "                app_config_short = dict(zip([name.removeprefix(f'sw.{test[\"sw.app\"]}.').removeprefix('sweep.') \n",
    "                                             for name in test[app_cols]  .to_dict()], test[app_cols]  .to_dict().values()))\n",
    "                sweep_short      = dict(zip([name.removeprefix(f'sw.{test[\"sw.app\"]}.sweep.')                  \n",
    "                                             for name in test[sweep_cols].to_dict()], test[sweep_cols].to_dict().values()))\n",
    "\n",
    "                # Calculate output path for specific test\n",
    "                test_path = output_dir / hw_config / app_config / slugify(str(sweep))\n",
    "                test['path'] = str(test_path)\n",
    "\n",
    "                # Print the config and sw specific config to the corresponding directory\n",
    "                write_test_configs(test.to_dict(), app_config_short, test_path)\n",
    "                \n",
    "                # compile_sw(test, sw_config, output_dir)\n",
    "                # run_test()\n",
    "                # post_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213017b-a0ff-4e47-80f4-fa029cda2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.groupby(by='hw.config').get_group('full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08c9b6-82de-4e36-a4bc-90fca987b151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
